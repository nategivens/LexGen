{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-sleep",
   "metadata": {},
   "source": [
    "# Transition Matrix Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-retailer",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "casual-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nate_givens_toolkit import cloud_io as cloud\n",
    "from nate_givens_toolkit import local_io as local\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-belle",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driving-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_CORPORA_DIR = 'clean_corpora/'\n",
    "DATA_DIR = 'data_files/'\n",
    "TRANS_MATS_DIR = 'transition_matrices/'\n",
    "BUCKET = 'lexgen'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-water",
   "metadata": {},
   "source": [
    "## Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-relationship",
   "metadata": {},
   "source": [
    "### Read in Data Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-interaction",
   "metadata": {},
   "source": [
    "#### Clean Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dated-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpora = cloud.read_csv_from_s3('clean_corpora_inventory.dat', DATA_DIR, BUCKET, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "featured-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw_corpora_filename</th>\n",
       "      <th>last_load_dtime</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_50k_2018_A.txt</td>\n",
       "      <td>en_50k_2018.txt</td>\n",
       "      <td>2021-04-01 01:07:27.259981</td>\n",
       "      <td>Cleaned version of en_50k_2018 with top 200 wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de_50k_2018_A.txt</td>\n",
       "      <td>de_50k_2018.txt</td>\n",
       "      <td>2021-04-06 20:25:02.967162</td>\n",
       "      <td>Cleaned version of de_50k_2018 with top 200 wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af_full_2018_A.txt</td>\n",
       "      <td>af_full_2018.txt</td>\n",
       "      <td>2021-04-07 20:30:13.085269</td>\n",
       "      <td>Cleaned version of af_full_2018 with top 200 w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename raw_corpora_filename             last_load_dtime  \\\n",
       "0   en_50k_2018_A.txt      en_50k_2018.txt  2021-04-01 01:07:27.259981   \n",
       "1   de_50k_2018_A.txt      de_50k_2018.txt  2021-04-06 20:25:02.967162   \n",
       "2  af_full_2018_A.txt     af_full_2018.txt  2021-04-07 20:30:13.085269   \n",
       "\n",
       "                                                note  \n",
       "0  Cleaned version of en_50k_2018 with top 200 wo...  \n",
       "1  Cleaned version of de_50k_2018 with top 200 wo...  \n",
       "2  Cleaned version of af_full_2018 with top 200 w...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpora.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-failing",
   "metadata": {},
   "source": [
    "#### Transition Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "permanent-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mats = cloud.read_csv_from_s3('trans_mats_inventory.dat', DATA_DIR, BUCKET, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quantitative-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>clean_corpus_filename</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>last_load_dtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_50k_2018_A-tm1.dat</td>\n",
       "      <td>en_50k_2018_A.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-02 01:26:32.184511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_50k_2018_A-tm2.dat</td>\n",
       "      <td>en_50k_2018_A.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-02 01:26:32.184511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_50k_2018_A-tm3.dat</td>\n",
       "      <td>en_50k_2018_A.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-04-02 01:26:32.184511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_50k_2018_A-tm4.dat</td>\n",
       "      <td>en_50k_2018_A.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-04-02 01:26:32.184511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de_50k_2018_A-tm1.dat</td>\n",
       "      <td>de_50k_2018_A.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-07 20:03:20.399818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename clean_corpus_filename  prefix_len  \\\n",
       "0  en_50k_2018_A-tm1.dat     en_50k_2018_A.txt           1   \n",
       "1  en_50k_2018_A-tm2.dat     en_50k_2018_A.txt           2   \n",
       "2  en_50k_2018_A-tm3.dat     en_50k_2018_A.txt           3   \n",
       "3  en_50k_2018_A-tm4.dat     en_50k_2018_A.txt           4   \n",
       "4  de_50k_2018_A-tm1.dat     de_50k_2018_A.txt           1   \n",
       "\n",
       "              last_load_dtime  \n",
       "0  2021-04-02 01:26:32.184511  \n",
       "1  2021-04-02 01:26:32.184511  \n",
       "2  2021-04-02 01:26:32.184511  \n",
       "3  2021-04-02 01:26:32.184511  \n",
       "4  2021-04-07 20:03:20.399818  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_mats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-discrimination",
   "metadata": {},
   "source": [
    "### Select Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detailed-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus_filename = 'af_full_2018_A.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-brooks",
   "metadata": {},
   "source": [
    "### Create Output Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "certain-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_names = [f'{clean_corpus_filename.replace(local.get_file_extension(clean_corpus_filename), \"\")}-tm{x}.dat' for x in range(1,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-briefing",
   "metadata": {},
   "source": [
    "### Process Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "radical-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = cloud.read_csv_from_s3(clean_corpus_filename, CLEAN_CORPORA_DIR, BUCKET, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hungry-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>5.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nie</td>\n",
       "      <td>5.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ek</td>\n",
       "      <td>5.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>5.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>het</td>\n",
       "      <td>5.77427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word     freq\n",
       "0  die  5.77427\n",
       "1  nie  5.77427\n",
       "2   ek  5.77427\n",
       "3   is  5.77427\n",
       "4  het  5.77427"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "facial-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of 4 dictionaries, one for each transition matrix\n",
    "tms = [{} for i in range(4)]\n",
    "# the transition matrix dictionaries will be nested dictionaries with structure as follows:\n",
    "# Outer Dictionary key: the prefix (1 - 4 characters)\n",
    "# Outer Dictionary value: the Inner Dictionary\n",
    "# Inner Dictionary key: the suffix (1 character)\n",
    "# Inner Dictionary value: the frequency of transitioning to that suffix given the prefix (Outer Dictionary key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cutting-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of 4 dictionaries to track total frequency for each from_substr\n",
    "# this will be used to normalize probability conditioned on from_substr\n",
    "from_substr_freqs = [{} for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "visible-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the clean corpus and create transition matrix dictionaries and cumulative frequency dictionaries\n",
    "for row in clean_corpus.itertuples(index=False):\n",
    "    word = f' {row[0]} '\n",
    "    frequency = float(row[1])\n",
    "    for i in range(1, len(word)):\n",
    "        to_char = word[i]\n",
    "        # for each character in the word, we're going to iterate through our substring lengths = (1, 2, 3, 4)\n",
    "        # of course, the indices are actually t = (0, 1, 2, 3)\n",
    "        for t in range(4):\n",
    "            # populate from_substr with the 1, 2, 3 or 4-char substring preceding to_char\n",
    "            # if there are not enough characters, set from_substr to None\n",
    "            from_substr = word[i-t-1:i] if i > t else None\n",
    "            \n",
    "            if from_substr in tms[t].keys():\n",
    "                if to_char in tms[t][from_substr].keys():\n",
    "                    tms[t][from_substr][to_char] = tms[t][from_substr][to_char] + frequency\n",
    "                else:\n",
    "                    tms[t][from_substr][to_char] = frequency\n",
    "            elif from_substr is not None:\n",
    "                tms[t][from_substr] = {to_char: frequency}\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if from_substr in from_substr_freqs[t].keys():\n",
    "                from_substr_freqs[t][from_substr] = from_substr_freqs[t][from_substr] + frequency\n",
    "            elif from_substr is not None:\n",
    "                from_substr_freqs[t][from_substr] = frequency\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "changed-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the frequencies\n",
    "for t in range(4):\n",
    "    for key in from_substr_freqs[t].keys():\n",
    "        total_freq = from_substr_freqs[t][key]\n",
    "        for sub_key in tms[t][key].keys():\n",
    "            tms[t][key][sub_key] = tms[t][key][sub_key] / total_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "phantom-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert transition matrix dictionaries to Pandas dataframes\n",
    "tm_dfs = []\n",
    "for t in range(4):\n",
    "    substr_col = []\n",
    "    to_char_col = []\n",
    "    frequency_col = []\n",
    "    for outer_key in tms[t].keys():\n",
    "        for inner_key, value in tms[t][outer_key].items():\n",
    "            substr_col.append(outer_key)\n",
    "            to_char_col.append(inner_key)\n",
    "            frequency_col.append(value)\n",
    "    data = list(zip(substr_col, to_char_col, frequency_col))\n",
    "    df = pd.DataFrame(data, columns=['from_str', 'to_char', 'rel_frequency'])\n",
    "    tm_dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-excess",
   "metadata": {},
   "source": [
    "### Save Transition Matrices to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bound-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write transition matrices to S3\n",
    "for tm_df, tm_name in zip(tm_dfs, tm_names):\n",
    "    cloud.write_csv_to_s3(tm_name, TRANS_MATS_DIR, BUCKET, tm_df, sep='|', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-russell",
   "metadata": {},
   "source": [
    "### Update Transition Matrices Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "distributed-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dtime = str(datetime.utcnow())\n",
    "t = 1\n",
    "for tm_name in tm_names:\n",
    "    new_row = {\n",
    "        'filename' : tm_name\n",
    "        ,'clean_corpus_filename' : clean_corpus_filename\n",
    "        ,'prefix_len' : t\n",
    "        ,'last_load_dtime' : load_dtime\n",
    "    }\n",
    "    t += 1\n",
    "    trans_mats = trans_mats.append(new_row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "loving-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud.write_csv_to_s3('trans_mats_inventory.dat', DATA_DIR, BUCKET, trans_mats, sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-scholarship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexgen",
   "language": "python",
   "name": "lexgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
